The One Hundred Year Study on AI article reflected upon AI’s opportunities and uncertainties that the world might encounter ahead, along with highlighting topics that would require additional study. Throughout the piece, extensive details showcased the possible future of AI and human life, however, one such idea struck as a challenge to me: the loss of control of AI systems. These systems acting out of accordance with humans might even pose a threat to humanity. This possibility has been expressed extensively in sci-fi films and even classics like George Orwell's 1984. The book discussing the idea of a dystopic ‘big brother’ watching seems tough to question the rise of AI superintelligences. This not only affects the civil liberties-  a constitutional guarantee for the majority of the countries but also highlights the dangerous likelihood of intelligence explosion; the technological singularity. The article mentions that “Private and public dollars should be directed toward interdisciplinary teams capable of analyzing AI from multiple angles”[Pg44] however, it doesn’t address the fact on how the general public will take this AI intrusion into their daily lives. We are unaware of people’s response to intelligent applications and robots in the environment– services exceeding more than just smartphones and smart cars. Additionally, non-experts on such fields are more or less unaware of the key issues and developmental prospects of AI, so their anxieties might also lead to slow down of the AI processes that otherwise might be beneficial. I believe a major drawback not discussed within this article relates to these multiple risks of poor understandings of people from various backgrounds even though the safety and autonomy factor has been briefly discussed within this study[Pg36]. The psychological implications of such imperatives do not seem to be taken very seriously into consideration in this study. The article itself additionally states the fact that “Tradeoffs between promoting innovation and regulating for safety are difficult ones”[Pg45]. Even though addressing the problem, it does not define a way that this issue might be solved. I believe that the worries and fears need to be addressed even if they are unwarranted. Reflecting further upon the value of proactive efforts mitigating concerns and ensuring better outcomes need to be strategized as well.In my personal opinion, I feel that AI and human development should go hand in hand. Prioritizing only one out f them is bound to be inefficient in terms of society-economic, and political capital. There are great opportunities in this realm for deploying ways endowing computational systems and enabling machines and people to fluidly work together, where each of them contributes to the overall solution system. Preferring and biasing opinions on the betterment of either one are bound to cause society’s underproduction and improper resource utilization– an issue that has been the recurrent theme of the discussion thus far.–Niharika Tomar